# AudioContext: The Audio Graph

Web Audio uses a **node-based architecture**:

![Audio Context Graph](/slides/audio-context-graph.png)

Like visual programming for audio!

---

## How Nodes Work

```js
const ctx = new AudioContext()

// Create nodes
const source = ctx.createMediaStreamSource(micStream)
const analyser = ctx.createAnalyser()
const gain = ctx.createGain()

// Connect the graph
source.connect(analyser)
analyser.connect(gain)
gain.connect(ctx.destination)
```

Each node processes audio and passes it along

---

## Real-World: AI Vocal Compositor

Built a **MIDI compositor with voice sync**:

- ğŸ¹ MIDI sequencer for instruments
- ğŸ¤ AI-generated vocals synced to timeline
- ğŸšï¸ Real-time mixing and effects
- ğŸ“Š Waveform visualization

All orchestrated through AudioContext nodes

ğŸ”— [Try Yating AI Vocal Studio](https://studio.yating.tw/music/ai-vocal) â€” Production MIDI compositor with piano preview & voice sync

![AI Vocal Page](/slides/ai-vocal-page.png)

[Try AudioContext Demo](/api/audiocontext)
